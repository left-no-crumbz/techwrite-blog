<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bits and Bytes</title>
    <link rel="stylesheet" href="../css/article.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap" rel="stylesheet">
    <link rel="icon" href="../img/home/Logo.svg">


</head>

<body>
    <nav class="navbar flex">
        <a class="logo flex" href="../index.html#home">
            <img src="../img/home/Logo.svg" alt="An image of the logo of the website" width="48" height="auto" decoding="async">
            <h1>Bits and Bytes</h1>
        </a>

        <div class="nav flex">
            <a href="../index.html#home">Home</a>
            <a href="../index.html#articles">Articles</a>
        </div>
    </nav>

    
    <main>
        <h1 class="title">Will Artificial Intelligence Replace Software Developers?</h1>
        <h2 class="subtitle">Long story short, no they won’t; here’s why.</h2>
        
        <div class="author-container flex">
            <img class="author-img" src="../img/authors/dwayne.webp" alt="An image of the article author">
            
            <div class="name-date-container grid">
                <div class="author-name">Kirsten Dizon</div>
                <div class="read-length">3 min read</div>
                <div class="period">&#183;</div>
                <div class="date">Aug 30, 2024</div>
            </div>
        </div>
        
        <figure>
            <img src="../img/ai/ai.jpg" alt="A cartoon panel of a worker replaced by AI">
            <figcaption>(image from <a href="https://www.reddit.com/r/Geico/comments/1f2htlg/things_are_going_great/" target="_blank" referrerpolicy="noopener noreferrer nofollow">Reddit</a>)</figcaption>
        </figure>
        
        <p>When non-technical people use the term AI nowadays, they are mostly referring to Large Language Models (LLM) like ChatGPT wherein a user can ask and command it through prompts. Since the chatbot was trained on multitudes of data, it can answer and do several things — including programming — with little to no failure.</p>

       <p>The employment concern now arises with some CEOs doing massive layoffs and opting for an “AI-native” workplace replacing everything with AI chatbots (Estrada, 2024), which raises the question, will AI replace software developers as well?</p>
       
       <p>Before we tackle the topic, let's first talk about why. Why would any sane CEO opt for an LLM rather than real people? Price of course! According to Indeed (2023), the average salary of software engineers in the US is $105,394. Multiply that by seven which is the optimal head count for any software engineering team (Ilyina, 2020) which yields a total of $737,758. Yikes. As opposed to the pricing of GPT4 which is $30 per user under their Teams pricing. Now you understand why they are considering replacing us.</p>
       
       <p>However, that isn't a great idea, and here's why.</p>

       <h3>Software Development Is More Than Coding</h3>

       <p>When non-technical people think about software development, they mostly think about coding — the same act that any LLM can do faster than the average person. However, they fail to see that programming is a multifaceted skill; in other words, software development is more than coding.</p>
       
       <p>Imagine this: a client asks for features that don't fit the app's main purpose. This is called 'scope creep.' It's up to the developer to explain why these features might not be a good idea and how they could mess up the app. An AI, on the other hand, would just do what the client asks, even if it's not the best thing for the app.</p>

       <h3>LLMs don’t work like magic</h3>
       
       <p>Most non-technical CEOs and investors have a notion that AI models can keep getting better and better forever, just by giving them more data. And truly, I can understand why they have that notion. It's easy to see why they think that since the models have improved a lot in the past. But if you look at the latest results, you'll notice that they're not improving as much anymore (Marcus, 2024).</p>
       
       <p>Take a look at the image below taken from Marcus (2024):</p>
       
       <figure>
           <img src="../img/ai/benchmark.webp" alt="MMLU benchmark of different GPT versions" loading="lazy" decoding="async">
           <figcaption>Fig 1. MMLU benchmark of different GPT versions (image from <a href="https://garymarcus.substack.com/p/evidence-that-llms-are-reaching-a" target="_blank" referrerpolicy="noopener noreferrer nofollow">Marcus on AI</a>)</figcaption>
       </figure>
       
       <p>We see early versions of ChatGPT improved a lot, but now the improvements are getting smaller. And it even looks like there might be a limit to how much they can learn.</p>

       <h3>LLMs are not good at solving new problems</h3>

       <p>To explain this better, let me give you an analogy. Think of an LLM as a well-read librarian. The librarian has read several books and articles. When someone asks a question, the librarian uses their knowledge to find the most relevant information and provide a response. This is how an LLM works — it can only operate on things it knows.</p>

       <p>As a result, it cannot answer things that weren't included in its training data. That is why models like ChatGPT have a knowledge cut-off date, meaning that any data beyond that date was not included in the training, and as a result, ChatGPT doesn't know it.</p>

       <p>Imagine creating an innovative solution that solves a problem that no one has solved before. Of course, ChatGPT wouldn't be able to solve it because it hasn't been trained on that specific problem. Udandarao et al. (2024) reinforce this in their journal where they conclude that it would involve inconceivable amounts of data to produce a model capable of answering new problems that have never been encountered before.</p>

       <h3>Conclusion</h3>

       <p>So, in conclusion, it is sufficient to say that AI won’t be replacing software developers anytime soon. While it is a formidable tool, it's not a magic wand. It can't replicate the human touch — the creativity and nuanced understanding that's essential for truly innovative software.</p>

       <p> Instead, we should treat AI as an additional tool in a developer’s arsenal. The future isn't about AI replacing developers; it's about developers harnessing AI to create even more groundbreaking solutions.</p>

       <hr>

        <h3>References</h3>
        <p class="reference">Estrada, S. (2024, July 10). <span class="apa-title">Exclusive: Intuit is laying off 1,800 employees due to AI transformation. </span> Fortune. <a href="https://fortune.com/2024/07/10/intuit-layoffs-email-hiring-ai-transformation/" target="_blank" rel="noopener noreferrer nofollow">https://fortune.com/2024/07/10/intuit-layoffs-email-hiring-ai-transformation/</a></p>
        <p class="reference">Ilyina, A. (2020). <span class="apa-title">What is the typical team size for a software development project? </span> Syberry.com. <a href="https://www.syberry.com/blog/typical-size-team/" target="_blank" rel="noopener noreferrer nofollow">https://www.syberry.com/blog/typical-size-team/</a></p>
        <p class="reference">Indeed. (2023). <span class="apa-title">How much does A software engineer make in the United States? </span> Www.indeed.com. <a href="https://www.indeed.com/career/software-engineer/salaries" target="_blank" rel="noopener noreferrer nofollow">https://www.indeed.com/career/software-engineer/salaries</a></p>
        <p class="reference">Marcus, G. (2024, April 13). <span class="apa-title">Evidence that LLMs are reaching a point of diminishing returns - and what that might mean. </span> Substack.com; Marcus on AI. <a href="https://garymarcus.substack.com/p/evidence-that-llms-are-reaching-a" target="_blank" rel="noopener noreferrer nofollow">https://garymarcus.substack.com/p/evidence-that-llms-are-reaching-a</a></p>
        <p class="reference">Udandarao, V., Prabhu, A., Ghosh, A., Sharma, Y., Torr, P. H. S., Bibi, A., Albanie, S., & Bethge, M. (2024, April 8). <span class="apa-title">No “zero-shot” without exponential data: Pretraining concept frequency determines multimodal model performance. </span> ArXiv.org. <a href="https://doi.org/10.48550/arXiv.2404.04125" target="_blank" rel="noopener noreferrer nofollow">https://doi.org/10.48550/arXiv.2404.04125</a></p>

    </main>
</body>
</html>